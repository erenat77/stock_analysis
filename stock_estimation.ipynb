{"cells":[{"metadata":{},"cell_type":"markdown","source":"## STOCK PRICE ESTIMATION"},{"metadata":{},"cell_type":"markdown","source":"## 1. Import the std libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"#stock estimations\n\n#1.importing the libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport tensorflow\nimport sys\nimport os\nimport sklearn\nimport sklearn.preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2.load the data\ndf_train = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the correlations\ncorrmat = df_train.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(corrmat, vmax=1, square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize the stock over tiem\nplt.figure(figsize=(15, 5));\n\nplt.subplot(1,2,1);\nplt.plot(df_train.open.values, color='red', label='open')\nplt.plot(df_train.close.values, color='green', label='close')\nplt.plot(df_train.low.values, color='blue', label='low')\nplt.plot(df_train.high.values, color='black', label='high')\nplt.title('stock price')\nplt.xlabel('time [days]')\nplt.ylabel('price')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2);\nplt.plot(df_train.volume.values, color='black', label='volume')\nplt.title('stock volume')\nplt.xlabel('time [days]')\nplt.ylabel('volume')\nplt.legend(loc='best');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# take a close values for the models\ntrainset = df_train.iloc[:,1:2].values\ntrainset[:5,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3.Manuplate the data \n#a.drop_volume\n#normalize\n#create train val and test data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#standartization\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0,1))\ntraining_scaled = sc.fit_transform(trainset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_scaled[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating sequence data for the input\nx_train = []\ny_train = []\n\nlook_back=60 \n\nfor i in range(look_back,df_train.shape[0]):\n    x_train.append(training_scaled[i-look_back:i])\n    y_train.append(training_scaled[i,0])\n    \nx_train,y_train = np.array(x_train),np.array(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense,TimeDistributed,Bidirectional\nfrom keras.layers import LSTM,Input,Conv1D,TimeDistributed\nfrom keras.layers import Dropout,Activation\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import SGD,Adagrad,Adam\nfrom keras.losses import Huber\nfrom keras import losses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = Sequential([\n    LSTM(100,return_sequences=True,input_shape=(None,1)),\n    Dropout(0.6),\n    Bidirectional(LSTM(100,return_sequences=True)),\n    Dropout(0.6),\n    Bidirectional(LSTM(100,return_sequences=True)),\n    Dropout(0.6),\n    Bidirectional(LSTM(100)),\n    Dropout(0.4),\n    Dense(60),\n    Dropout(0.6),\n    Dense(30),\n    Dropout(0.35),\n    Dense(1),\n])\n\nlr_schedule = LearningRateScheduler(lambda epoch : 1e-8 * 10**(epoch/10))\noptimizer = Adam(lr=1e-8)\n\nmodel.compile(\n    optimizer = optimizer,\n    loss = losses.mean_squared_logarithmic_error,\n    metrics = ['mae']\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nstart = time.time()\n\nhistory = model.fit(x_train,\n                    y_train,\n                    epochs = 100,\n                    batch_size = 32,\n                    validation_split=0.2,\n                    verbose= True,\n                    callbacks=[lr_schedule])\n\nprint ('compilation time : ', time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.semilogx(history.history['lr'],history.history['val_loss'])\nplt.semilogx(history.history['lr'],history.history['loss'])\nplt.axis([1e-8,1e-1,0,0.2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input,Conv1D,TimeDistributed\n\nmodel = Sequential([\n    LSTM(100,return_sequences=True,input_shape=(None,1)),\n    Dropout(0.6),\n    Bidirectional(LSTM(100,return_sequences=True)),\n    Dropout(0.6),\n    Bidirectional(LSTM(100,return_sequences=True)),\n    Dropout(0.6),\n    Bidirectional(LSTM(100)),\n    Dropout(0.4),\n    Dense(60),\n    Dropout(0.6),\n    Dense(30),\n    Dropout(0.35),\n    Dense(1),\n])\n\nmodel.summary()\n\noptimizer = Adam(lr=7e-5)\n\nmodel.compile(\n    optimizer = optimizer,\n    loss = losses.mean_squared_logarithmic_error,\n    metrics = ['mae']\n)\n\nstart = time.time()\n\nhistory = model.fit(x_train,\n                    y_train,\n                    epochs = 250,\n                    batch_size = 32,\n                    validation_split=0.2,\n                    verbose= True)\n\nprint ('compilation time : ', time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load model parameters and continue to train the model\nfrom keras.models import load_model\n#model = load_model('../input/model_stock_price_estimation.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for loss\nplt.figure(figsize=(12, 5));\n\nplt.subplot(2,2,1);\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n\nplt.figure(figsize=(12, 5));\nplt.subplot(2,2,2);\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss ZOOMED')\n\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.axis([100,400,0,0.005])\nplt.show()\n\n# summarize history for loss\nplt.figure(figsize=(12, 5));\nplt.subplot(2,2,3);\nplt.plot(history.history['mae'])\nplt.plot(history.history['val_mae'])\nplt.title('model mae')\nplt.ylabel('mae')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../input/model_stock_price_estimation.h5')  # creates a HDF5 file 'my_model.h5'\n# del model  # deletes the existing model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# returns a compiled model\nmodel = load_model('model_stock_price_estimation.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the test data for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets prepare the test data for prediction\n#load the test data and take close and volume data for model\n\ndf_test = pd.read_csv('../input/test.csv')\n\nreal_stock_price = df_test.iloc[:,1:2].values\nreal_stock_price.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_stock_price[:65]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Plot the real stock price for 78 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8));\nplt.plot(real_stock_price[:,0])\nplt.title('test_stock_price')\nplt.ylabel('stock price')\nplt.xlabel('days')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict and plot the result against real data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import newaxis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_results_multiple(predicted_data, true_data,lookback,length):\n    plt.plot(sc.inverse_transform(true_data.reshape(-1, 1))[lookback:lookback+length])\n    plt.plot(sc.inverse_transform(np.array(predicted_data).reshape(-1, 1)))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict lenght consecutive values from a real one\ndef predict_sequences_multiple(model, firstValue,length):\n    prediction_seqs = []\n    curr_frame = firstValue\n    print(\"Prediction in transformed format\")\n    for i in range(length): \n        predicted = []        \n        \n        #print(model.predict(curr_frame[newaxis,:,:]))\n        predicted.append(model.predict(curr_frame[newaxis,:,:]))\n        \n        curr_frame = curr_frame[0:]\n        #inserted prediction as an input for the next cycle\n        curr_frame = np.insert(curr_frame[0:],len(curr_frame), predicted[-1], axis=0)\n        #removed the first values from the top\n        curr_frame = curr_frame[1:]\n        \n        prediction_seqs.append(predicted[-1])\n        \n    return prediction_seqs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#take the first 30 (look_back) values and predict the rest\ninputs=df_test.iloc[:look_back,1:2].values\ninputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the input values\ninputs=sc.transform(inputs)\ninputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_length=40\n\n#model = load_model('model_stock_price_estimation.h5')\npredictions = predict_sequences_multiple(model, inputs, predict_length)\n\n#print(\"Prediction are converted to orginal values\")\nprint(sc.inverse_transform(np.array(predictions).reshape(-1, 1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results_multiple(predictions, \n                      sc.transform(df_test.iloc[look_back:,1:2].values), \n                      look_back,predict_length)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda root]","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"}},"nbformat":4,"nbformat_minor":1}